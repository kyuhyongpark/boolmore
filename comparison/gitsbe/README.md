# Installation

## Install Gitsbe

See https://druglogics.github.io/druglogics-doc/gitsbe-install.html to install gitsbe.
Note that the installation didn't work on Windows.
Below worked with Ubuntu on Windows subsystem for linux (WSL).

1. install JDK
    `sudo apt install openjdk-21-jdk-headless`
2. install maven
    `sudo apt-get install maven`
3. add JAVA_HOME
    add following line to .profile at home
    `export JAVA_HOME="/usr/lib/jvm/java-21-openjdk-amd64"`
4. install Gitsbe
    ```
    git clone https://github.com/druglogics/gitsbe.git
    cd gitsbe
    mvn clean install
    ```
5. test run
    ```
    cd example_run_ags
    java -cp ../target/gitsbe-1.3.1-jar-with-dependencies.jar eu.druglogics.gitsbe.Launcher --project=test --network=toy_ags_network.sif --trainingdata=toy_ags_training_data.tab --config=toy_ags_config.tab --modeloutputs=toy_ags_modeloutputs.tab
    ```

## (Optional) Install mpbn

Using mpbn to calculate trapspaces offer a significant speedup when the network size is large. For our case study, however, the default method of Gitsbe was significantly faster.

1. install mpbn
    ```
    sudo apt update
    sudo apt install build-essential
    sudo apt-get install python3-dev

    pip install mpbn
    ```

    Download `mpbn-attractors.py` and `model.bnet` from https://github.com/druglogics/druglogics-dep and test run
    ```
    wget https://raw.githubusercontent.com/druglogics/druglogics-dep/refs/heads/master/mpbn-attractors.py
    wget https://raw.githubusercontent.com/druglogics/druglogics-dep/refs/heads/master/model.bnet
    
    python mpbn-attractors.py model.bnet
    ```

2. allow Gitsbe to access mpbn
    See https://github.com/druglogics/druglogics-dep#readme.

    For example, in file `home/user_name/.profile`, add
    ```
    export MPBN_HOME=/pathTo/dir-that-has-the-mpbn-attractors.py
    ```
    so that mpbn-attractors.py is accessible at the environment variable MPBN_HOME

# ABA case study

## convert ABA case study data

Run `conversion.ipynb`. This converts the baseline start model into list of edges in sif format. It also adds all extra edges specified in the json file to the list. Note that we cannot enforce constraints nor distinguish the original edges from the extra edges.
Since an interaction graph cannot distinguish source nodes from constant nodes, Gitsbe considers all constant nodes as source nodes. ABA model has 22 constant nodes, and considering them as source nodes makes it very difficult to enumerate attractors. For this reason, we substitute the constant node values to other functions (aka percolate). This eliminates 24 nodes (22 original constants and 2 extra nodes fixed by percolating constant nodes).
The result is stored as `ABA_A_network.sif`. Minor note that certain node names are changed, since Gitsbe does not allow certain characters in node names.

`conversion.ipynb` also converts input for boolmore into training data for Gitsbe. Source node values and perturbations are added as `Condition`. Experiments that have the same perturbation conditions are grouped together for faster computation. Observation categories "OFF", "OFF/Some", "Some", "Some/ON", "ON" is assigned values 0, 0.25, 0.5, 0.75, 1.0 respectively as `Response`. Each `Condition`-`Response` pair is assigned a weight equal to the number of observation so that each observation is treated equally.

For example,

| ID | Score |   Source  |        Perturbation        | Observed node | Categorization |
| -- | ----- | --------- | -------------------------- | ------------- | -------------- |
|  1 | 	1.0  |  Source=0 | Mediator1 KO, Mediator2 CA |         Sink1 |             ON |
|  2 |  1.0  |  Source=0 | Mediator1 KO, Mediator2 CA |         Sink2 |       OFF/Some |

will be converted to

```
Condition
Source:0	Mediator1:0	Mediator2:1
Response
Sink1:1	Sink2:0.25
Weight:2
```

Note that experiments that consider the 24 nodes that got eliminated due to percolation are ignored. The result is stored as `ABA_A_training_data.tab`. 

Finally, `conversion.ipynb` also creates `ABA_A_gitsbe.tsv`, which is an experimental data file used to score the models generated by Gitsbe using the boolmore hierarchy scoring method. It omits experiments that have the constant nodes perturbed or observed. It also has certain node names modified.


## Running Gitsbe on ABA case study

Create directory `ABA` in the Gitsbe repository, and copy
```
ABA_A_network.sif
ABA_A_training_data.tab
ABA_config.tab
ABA_modeloutputs.tab
```
And run,
```
java -cp ../target/gitsbe-1.3.1-jar-with-dependencies.jar eu.druglogics.gitsbe.Launcher --project=ABA_A --network=ABA_A_network.sif --trainingdata=ABA_A_training_data.tab --config=ABA_config.tab --modeloutputs=ABA_modeloutputs.tab
```

This runs 6 simulations in parallel, where each simulation consisted of 400 generations with 400 models per generation.
Each simulation generates 3 best models, resulting in 18 models.

## Results

Result of a Gitsbe run is in the `ABA_A_20241105_214621` directory.

Whole process took ~13 hours. We score the models using the method of boolmore, based on the 429 experimental results that Gitsbe could process.

The 18 Gitsbe models had max 305.0/429 (71.1%) score and max 343.7/429 (80.1%) attactor agreement(non-hierarchy score).  
The 15 boolmore models had min 334.3/429 (77.9%) score and min 359.3/429 (83.8%) attactor agreement(non-hierarchy score).

Also note that Gitsbe models did not follow any biological constraints, as they cannot be specified in Gitsbe.
For example, all 18 models had a function `Closure, Microtubule_Depolymerization`, which is biologically unrealistic.

See `compare.ipynb` to reproduce the comparison results.
